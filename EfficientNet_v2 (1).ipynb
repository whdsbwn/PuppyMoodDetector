{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Q-nVCrLPpg6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "from google.colab import files, drive\n",
        "\n",
        "# # Keggle API\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# # Move kaggle.json to .kaggle & Authorization\n",
        "# !mkdir -p ~/.kaggle\n",
        "# !mv kaggle.json ~/.kaggle/\n",
        "\n",
        "# !chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Outside of Google Drive\n",
        "# !kaggle datasets download -d dougandrade/dog-emotions-5-classes"
      ],
      "metadata": {
        "id": "qiBPMwMcPtsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/YAI/24Summer_Toy_Project')"
      ],
      "metadata": {
        "id": "nRVgivUzPwAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Unzip\n",
        "# with zipfile.ZipFile('/content/drive/MyDrive/YAI/24Summer_Toy_Project/preprocessed_images.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall(path='/content/drive/MyDrive/YAI/24Summer_Toy_Project')"
      ],
      "metadata": {
        "id": "Bxl09rJJQb7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import EfficientNet_V2_S_Weights, efficientnet_v2_s\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.utils.data.dataset import random_split\n",
        "from PIL import Image\n",
        "from torchvision import datasets, models\n",
        "from copy import deepcopy\n",
        "import cv2\n",
        "import glob\n",
        "import argparse\n",
        "import time\n",
        "import json\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "nzvqiDRXRtZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPUs를 검색 및 해결\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "    print(\"Running on TPU\")\n",
        "except ValueError:\n",
        "    print(\"No TPU found, using default strategy\")\n",
        "    strategy = tf.distribute.get_strategy()  # TPU가 없는 경우 기본 전략 사용 (예: CPU/GPU)"
      ],
      "metadata": {
        "id": "ewljbdhTiDuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Datasets"
      ],
      "metadata": {
        "id": "jo45GEjHNsu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 분할된 데이터셋을 저장할 경로\n",
        "output_root_dir = '/content/drive/MyDrive/YAI/24Summer_Toy_Project/preprocessed_images'\n",
        "train_dir = os.path.join(output_root_dir, 'train')\n",
        "val_dir = os.path.join(output_root_dir, 'val')\n",
        "test_dir = os.path.join(output_root_dir, 'test')"
      ],
      "metadata": {
        "id": "rH9f71__TPzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 로드 함수\n",
        "def load_npy_file(file_path):\n",
        "    return np.load(file_path)\n",
        "def create_dataset_from_directory(directory, batch_size=32, shuffle=True):\n",
        "    file_paths = []\n",
        "    labels = []\n",
        "    class_names = sorted(os.listdir(directory))\n",
        "\n",
        "    for label, class_name in enumerate(class_names):\n",
        "        class_dir = os.path.join(directory, class_name)\n",
        "        for file_name in os.listdir(class_dir):\n",
        "            if file_name.endswith('.npy'):\n",
        "                file_paths.append(os.path.join(class_dir, file_name))\n",
        "                labels.append(label)\n",
        "\n",
        "    file_paths = np.array(file_paths)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
        "\n",
        "    def load_and_preprocess_image(file_path, label):\n",
        "        image = tf.numpy_function(load_npy_file, [file_path], tf.float32)\n",
        "        image = tf.reshape(image, [300, 300, 3])  # 원본 이미지의 예상 shape을 지정합니다.\n",
        "        image = tf.image.resize(image, (224, 224))  # 이미지 크기 조정 (224x224)\n",
        "        image = image / 255.0  # 정규화\n",
        "        return image, label\n",
        "\n",
        "    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=len(file_paths))\n",
        "\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return dataset, class_names  # 이 부분에서 dataset과 class_names를 반환합니다.\n"
      ],
      "metadata": {
        "id": "N8ljuh3-PDM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NumpyDataset(Dataset):\n",
        "    def __init__(self, directory, transform=None):\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.class_names = sorted(os.listdir(directory))  # 클래스 이름\n",
        "        self.classes = {i: class_name for i, class_name in enumerate(self.class_names)}  # 클래스 인덱스를 이름으로 매핑\n",
        "\n",
        "        for class_name in self.class_names:\n",
        "            class_dir = os.path.join(directory, class_name)\n",
        "            if os.path.isdir(class_dir):\n",
        "                for file_name in os.listdir(class_dir):\n",
        "                    file_path = os.path.join(class_dir, file_name)\n",
        "                    if file_path.endswith('.npy'):\n",
        "                        img_array = np.load(file_path)\n",
        "                        label = self.class_names.index(class_name)\n",
        "                        self.data.append(img_array)\n",
        "                        self.labels.append(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # 만약 transform이 설정되어 있으면, transform을 적용\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "\n",
        "        return img, label\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s96yQZBrPv13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = NumpyDataset(train_dir)\n",
        "valset = NumpyDataset(val_dir)\n",
        "testset = NumpyDataset(test_dir)"
      ],
      "metadata": {
        "id": "LE2EtTbWlX9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Define"
      ],
      "metadata": {
        "id": "h5_Yu1q_Zhnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = models.efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.DEFAULT)\n",
        "\n",
        "# self.classifier = nn.Sequential(\n",
        "#     nn.Dropout(p=dropout, inplace=True),\n",
        "#     nn.Linear(lastconv_output_channels, num_classes),\n",
        "# )\n",
        "net.classifier[1] = nn.Linear(net.classifier[1].in_features, args.out_dim)\n",
        "if hasattr(args, 'dropout_rate'):\n",
        "    net.classifier.add_module(\"dropout\", nn.Dropout(args.dropout_rate)) # dropout 사용할 경우 모델 아키텍처에 추가\n",
        "\n",
        "# GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "net = net.to(device)"
      ],
      "metadata": {
        "id": "E3ahbuk9ZjmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training & Validation"
      ],
      "metadata": {
        "id": "ywhsxwi6UERR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, optimizer, criterion, args):\n",
        "    trainloader = torch.utils.data.DataLoader(trainset,\n",
        "                                              batch_size=args.train_batch_size,\n",
        "                                              shuffle=True, num_workers=2)\n",
        "    net.train()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = net(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = train_loss / len(trainloader)\n",
        "    train_acc = 100 * correct / total\n",
        "    return net, train_loss, train_acc"
      ],
      "metadata": {
        "id": "Agz_cNDeUJEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(net, criterion, args):\n",
        "    valloader = torch.utils.data.DataLoader(valset,\n",
        "                                            batch_size=args.test_batch_size,\n",
        "                                            shuffle=False, num_workers=2)\n",
        "    net.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in valloader:\n",
        "            images, labels = data\n",
        "\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss = val_loss / len(valloader)\n",
        "        val_acc = 100 * correct / total\n",
        "    return val_loss, val_acc"
      ],
      "metadata": {
        "id": "-KKQj6ZEeoEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(net, args):\n",
        "    testloader = torch.utils.data.DataLoader(testset,\n",
        "                                             batch_size=args.test_batch_size,\n",
        "                                             shuffle=False, num_workers=2)\n",
        "    net.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_acc = 100 * correct / total\n",
        "    return test_acc"
      ],
      "metadata": {
        "id": "1T9JRQymXGSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment"
      ],
      "metadata": {
        "id": "RQ9r6p_bW8y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def experiment(args):\n",
        "\n",
        "    net = models.efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.DEFAULT)\n",
        "\n",
        "    # self.classifier = nn.Sequential(\n",
        "    #     nn.Dropout(p=dropout, inplace=True),\n",
        "    #     nn.Linear(lastconv_output_channels, num_classes),\n",
        "    # )\n",
        "    net.classifier[1] = nn.Linear(net.classifier[1].in_features, args.out_dim)\n",
        "    if hasattr(args, 'dropout_rate'):\n",
        "        net.classifier.add_module(\"dropout\", nn.Dropout(args.dropout_rate)) # dropout 사용할 경우 모델 아키텍처에 추가\n",
        "\n",
        "    # GPU\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    net = net.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if args.optim == 'SGD':\n",
        "        optimizer = optim.SGD(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    elif args.optim == 'RMSprop':\n",
        "        optimizer = optim.RMSprop(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    elif args.optim == 'Adam':\n",
        "        optimizer = optim.Adam(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    else:\n",
        "        raise ValueError('In-valid optimizer choice')\n",
        "\n",
        "    # 스케줄러 정의\n",
        "    if args.scheduler == 'ReduceLROnPlateau':\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5)\n",
        "    elif args.scheduler == 'StepLR':\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "    else:\n",
        "        scheduler = None\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(args.epoch):  # loop over the dataset multiple times\n",
        "        ts = time.time()\n",
        "        net, train_loss, train_acc = train(net, optimizer, criterion, args)\n",
        "        val_loss, val_acc = validate(net, criterion, args)\n",
        "        te = time.time()\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        print('Epoch {}, Acc(train/val): {:2.2f}/{:2.2f}, Loss(train/val) {:2.2f}/{:2.2f}. Took {:2.2f} sec'.format(epoch, train_acc, val_acc, train_loss, val_loss, te-ts))\n",
        "\n",
        "        # 스케줄러 업데이트\n",
        "        if scheduler is not None:\n",
        "            if args.scheduler == 'ReduceLROnPlateau':\n",
        "                scheduler.step(val_loss)\n",
        "            else:\n",
        "                scheduler.step()\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(net.state_dict(), 'your_best_model.pth')\n",
        "            print(f'Best model saved with accuracy: {best_acc:2.2f}')\n",
        "\n",
        "    result = {}\n",
        "    result['train_losses'] = train_losses\n",
        "    result['val_losses'] = val_losses\n",
        "    result['train_accs'] = train_accs\n",
        "    result['val_accs'] = val_accs\n",
        "    result['train_acc'] = train_acc\n",
        "    result['val_acc'] = val_acc\n",
        "    result['best_acc'] = best_acc\n",
        "    return vars(args), result"
      ],
      "metadata": {
        "id": "Gzi2dte1W-S4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "import json\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import pandas as pd\n",
        "\n",
        "def save_exp_result(setting, result):\n",
        "    exp_name = setting['exp_name']\n",
        "    del setting['epoch']\n",
        "    del setting['test_batch_size']\n",
        "\n",
        "    hash_key = hashlib.sha1(str(setting).encode()).hexdigest()[:6]\n",
        "    filename = './results/{}-{}.json'.format(exp_name, hash_key)\n",
        "    result.update(setting)\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(result, f)\n",
        "\n",
        "\n",
        "def load_exp_result(exp_name):\n",
        "    dir_path = './results'\n",
        "    filenames = [f for f in listdir(dir_path) if isfile(join(dir_path, f)) if '.json' in f]\n",
        "    list_result = []\n",
        "    for filename in filenames:\n",
        "        if exp_name in filename:\n",
        "            with open(join(dir_path, filename), 'r') as infile:\n",
        "                results = json.load(infile)\n",
        "                list_result.append(results)\n",
        "    df = pd.DataFrame(list_result) # .drop(columns=[])\n",
        "    return df"
      ],
      "metadata": {
        "id": "MppM4rqPf6AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiemt Parameters"
      ],
      "metadata": {
        "id": "atHS_hjWWr_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Random Seed Initialization ====== #\n",
        "seed = 123\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "args = parser.parse_args(\"\")\n",
        "args.exp_name = \"exp1_lr_model_code\"\n",
        "\n",
        "# ====== Model ====== #\n",
        "args.out_dim = 5\n",
        "args.act = 'relu'\n",
        "\n",
        "# ====== Regularization ======= #\n",
        "args.l2 = 0.00001\n",
        "\n",
        "# ====== Optimizer & Training ====== #\n",
        "args.optim = 'RMSprop' #'RMSprop' #SGD, RMSprop, ADAM...\n",
        "#args.lr = 0.0015\n",
        "args.lr_decay = 0.95\n",
        "#args.scheduler = 'ReduceLROnPlateau'\n",
        "args.epoch = 10\n",
        "\n",
        "args.dropout_rate = 0.2\n",
        "\n",
        "args.train_batch_size = 64\n",
        "args.test_batch_size = 128"
      ],
      "metadata": {
        "id": "Sv_byRKlWyFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Experiment Variable ====== #\n",
        "name_var1 = 'lr'\n",
        "name_var2 = 'scheduler'\n",
        "list_var1 = [0.1,0.01,0.001]\n",
        "list_var2 = ['ReduceLROnPlateau', 'StepLR']\n",
        "\n",
        "\n",
        "setattr(trainset, 'transform', None)\n",
        "setattr(valset, 'transform', None)\n",
        "setattr(testset, 'transform', None)\n",
        "\n",
        "for var1 in list_var1:\n",
        "    for var2 in list_var2:\n",
        "        setattr(args, name_var1, var1)\n",
        "        setattr(args, name_var2, var2)\n",
        "        print(args)\n",
        "\n",
        "        setting, result = experiment(deepcopy(args))\n",
        "        # save_exp_result(setting, result)"
      ],
      "metadata": {
        "id": "dAIUe_iKTmU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 완료 후 your_best_model.pth 로드\n",
        "net.load_state_dict(torch.load('your_best_model.pth'))\n",
        "\n",
        "# 테스트 실행\n",
        "test_acc = test(net, args)\n",
        "print(f'Test accuracy: {test_acc:.2f}%')"
      ],
      "metadata": {
        "id": "jcQlFuDRW5Qu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}