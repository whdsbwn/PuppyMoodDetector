{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V28"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"fQ8W_9G4-6SC","executionInfo":{"status":"error","timestamp":1724209400142,"user_tz":-540,"elapsed":733,"user":{"displayName":"김이정","userId":"17258177918259810377"}},"outputId":"8b869015-d85a-4177-cd5e-e08c6c3cd88c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/Shared drives/ToyProject'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-783c0d72bde5>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/Shared drives/ToyProject'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/Shared drives/ToyProject'"]}],"source":["import os\n","print(os.getcwd())\n","os.chdir('/content/drive/ToyProject')\n","print(os.getcwd())"]},{"cell_type":"code","source":["!ls\n","import zipfile\n","\n","# 업로드된 파일의 이름\n","file_name = \"train_images_5_class.zip\"\n","\n","# 압축 해제할 경로를 /content/로 설정\n","output_dir = \"/content/drive/MyDrive/ToyProject\"\n","\n","# 경로가 없으면 생성\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","# 압축 해제\n","with zipfile.ZipFile(file_name, 'r') as zip_ref:\n","    zip_ref.extractall(output_dir)\n","\n","print(\"파일이 압축 해제되었습니다.\")"],"metadata":{"id":"sPu11_SCB2sY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724133626237,"user_tz":-540,"elapsed":182198,"user":{"displayName":"조윤주","userId":"03220839207625740811"}},"outputId":"123c89ee-11c3-4a1e-edd3-cf7aeed93def"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["data.ipynb  train_images_5_class.zip\n","파일이 압축 해제되었습니다.\n"]}]},{"cell_type":"code","source":["# 이미지 전처리, 넘파이 배열 형식으로 저장\n","import os\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","from torchvision import transforms\n","\n","# 원본 데이터셋 경로\n","input_root_dir = '/content/drive/MyDrive/ToyProject/train_images_5_class'\n","\n","# 분할된 데이터셋을 저장할 경로\n","output_root_dir = '/content/drive/MyDrive/ToyProject/preprocessed_images'\n","train_dir = os.path.join(output_root_dir, 'train')\n","val_dir = os.path.join(output_root_dir, 'val')\n","test_dir = os.path.join(output_root_dir, 'test')\n","\n","# 데이터셋 폴더가 없으면 생성\n","for dir_path in [train_dir, val_dir, test_dir]:\n","    if not os.path.exists(dir_path):\n","        os.makedirs(dir_path)\n","\n","# 이미지 전처리 파이프라인 (EfficientNet에 맞게)\n","transform = transforms.Compose([\n","    transforms.Resize((300, 300)),  # 300x300 크기로 리사이즈\n","    transforms.ToTensor(),          # 이미지를 텐서로 변환\n","    transforms.Normalize(           # 정규화 (EfficientNet에 맞게)\n","        mean=[0.485, 0.456, 0.406],\n","        std=[0.229, 0.224, 0.225]\n","    ),\n","])\n","\n","# 각 클래스별로 데이터를 분할\n","for class_name in os.listdir(input_root_dir):\n","    class_dir = os.path.join(input_root_dir, class_name)\n","\n","    if not os.path.isdir(class_dir):\n","        continue\n","\n","    # 모든 이미지 파일 리스트\n","    images = os.listdir(class_dir)\n","\n","    # 8:1:1 비율로 데이터를 나눔\n","    train_images, test_images = train_test_split(images, test_size=0.2, random_state=42)\n","    val_images, test_images = train_test_split(test_images, test_size=0.5, random_state=42)\n","\n","    # 각 데이터셋에 해당하는 디렉토리 경로 설정\n","    train_class_dir = os.path.join(train_dir, class_name)\n","    val_class_dir = os.path.join(val_dir, class_name)\n","    test_class_dir = os.path.join(test_dir, class_name)\n","\n","    # 디렉토리가 없으면 생성\n","    for dir_path in [train_class_dir, val_class_dir, test_class_dir]:\n","        if not os.path.exists(dir_path):\n","            os.makedirs(dir_path)\n","\n","    # 이미지 전처리 후 NumPy 배열로 저장\n","    for img_name in train_images:\n","        img_path = os.path.join(class_dir, img_name)\n","        output_img_path = os.path.join(train_class_dir, os.path.splitext(img_name)[0] + '.npy')\n","        with Image.open(img_path) as img:\n","            img_processed = transform(img)  # 이미지 전처리\n","            img_array = img_processed.numpy()  # 텐서를 NumPy 배열로 변환\n","            np.save(output_img_path, img_array)  # NumPy 배열로 저장\n","\n","    for img_name in val_images:\n","        img_path = os.path.join(class_dir, img_name)\n","        output_img_path = os.path.join(val_class_dir, os.path.splitext(img_name)[0] + '.npy')\n","        with Image.open(img_path) as img:\n","            img_processed = transform(img)  # 이미지 전처리\n","            img_array = img_processed.numpy()  # 텐서를 NumPy 배열로 변환\n","            np.save(output_img_path, img_array)  # NumPy 배열로 저장\n","\n","    for img_name in test_images:\n","        img_path = os.path.join(class_dir, img_name)\n","        output_img_path = os.path.join(test_class_dir, os.path.splitext(img_name)[0] + '.npy')\n","        with Image.open(img_path) as img:\n","            img_processed = transform(img)  # 이미지 전처리\n","            img_array = img_processed.numpy()  # 텐서를 NumPy 배열로 변환\n","            np.save(output_img_path, img_array)  # NumPy 배열로 저장\n","\n","print(\"이미지가 8:1:1 비율로 나누어지고, 전처리된 후 NumPy 배열로 저장되었습니다.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H3FOk_arX-kh","executionInfo":{"status":"ok","timestamp":1724134108621,"user_tz":-540,"elapsed":382175,"user":{"displayName":"조윤주","userId":"03220839207625740811"}},"outputId":"a7cda397-8db3-473f-d159-b2e9685d9042"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["이미지가 8:1:1 비율로 나누어지고, 전처리된 후 NumPy 배열로 저장되었습니다.\n"]}]},{"cell_type":"code","source":["# 모델에 넣어보기\n","import torch\n","import numpy as np\n","from torchvision import models\n","\n","# EfficientNet-B3 모델 로드 (사전 학습된 가중치 사용)\n","weights = models.EfficientNet_B3_Weights.DEFAULT\n","model = models.efficientnet_b3(weights=weights)\n","model.eval()  # 모델을 평가 모드로 설정\n","\n","# 넘파이 배열로 저장된 전처리된 이미지 파일 경로\n","img_path = '/content/drive/MyDrive/ToyProject/preprocessed_images/test/alert/10131474585_997d88e066_b.npy'  # .npy 파일 경로\n","\n","# 넘파이 배열 로드\n","img_array = np.load(img_path)\n","\n","# NumPy 배열을 PyTorch 텐서로 변환\n","input_tensor = torch.tensor(img_array, dtype=torch.float32)\n","\n","# 배치 차원 추가 (모델 입력은 배치 단위로 해야 하므로)\n","input_batch = input_tensor.unsqueeze(0)\n","\n","# GPU 사용 가능 시, GPU로 모델과 데이터 이동\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","input_batch = input_batch.to(device)\n","\n","# 모델에 입력하여 예측 수행\n","with torch.no_grad():  # 그래디언트 계산 비활성화 (평가 단계이므로)\n","    output = model(input_batch)\n","\n","# 결과 해석 (가장 높은 확률의 클래스 추출)\n","_, predicted_idx = torch.max(output, 1)\n","print(f\"Predicted class index: {predicted_idx.item()}\")"],"metadata":{"id":"Rfb5HGxgZ-f4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","import urllib\n","\n","# ImageNet 클래스 인덱스 파일 다운로드\n","url = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\"\n","response = urllib.request.urlopen(url)\n","class_names = json.loads(response.read())\n","\n","# 243번 클래스 이름 확인\n","predicted_class_name = class_names[243]\n","print(f\"Predicted class name: {predicted_class_name}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I6A8nOFjaqLx","executionInfo":{"status":"ok","timestamp":1724134371598,"user_tz":-540,"elapsed":424,"user":{"displayName":"조윤주","userId":"03220839207625740811"}},"outputId":"9c04aa4c-75eb-43c9-d9e6-76ab6c68577c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted class name: Bullmastiff\n"]}]},{"cell_type":"code","source":["import shutil\n","\n","# 압축할 폴더 경로\n","folder_path = '/content/drive/MyDrive/ToyProject/preprocessed_images'\n","\n","# 압축 파일의 경로 (예: preprocessed_images.zip)\n","output_filename = '/content/drive/MyDrive/ToyProject/preprocessed_images.zip'\n","\n","# 폴더를 압축\n","shutil.make_archive(output_filename.replace('.zip', ''), 'zip', folder_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"KnVmaf92bC0R","executionInfo":{"status":"ok","timestamp":1724135781280,"user_tz":-540,"elapsed":965601,"user":{"displayName":"조윤주","userId":"03220839207625740811"}},"outputId":"a113a74b-8c7c-4bbf-927c-7619ad75ec8a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/ToyProject/preprocessed_images.zip'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["import tensorflow as tf\n","# TPU 설정 (옵션)\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPUs를 검색 및 해결\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.TPUStrategy(tpu)\n","    print(\"Running on TPU\")\n","except ValueError:\n","    print(\"No TPU found, using default strategy\")\n","    strategy = tf.distribute.get_strategy()  # TPU가 없는 경우 기본 전략 사용 (예: CPU/GPU)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wiBLLeWJjKAn","executionInfo":{"status":"ok","timestamp":1724220779711,"user_tz":-540,"elapsed":31080,"user":{"displayName":"조윤주","userId":"03220839207625740811"}},"outputId":"be1a9be7-7c61-4312-b2b2-bb242115ca0b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Running on TPU\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","import tensorflow as tf\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.applications import EfficientNetB3\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adamax\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","# Google 드라이브를 마운트\n","drive.mount('/content/drive')\n","\n","\n","\n","# TPU 설정 (옵션)\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPUs를 검색 및 해결\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.TPUStrategy(tpu)\n","    print(\"Running on TPU\")\n","except ValueError:\n","    print(\"No TPU found, using default strategy\")\n","    strategy = tf.distribute.get_strategy()  # TPU가 없는 경우 기본 전략 사용 (예: CPU/GPU)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XZT9TD_vl1oJ","executionInfo":{"status":"ok","timestamp":1724221561785,"user_tz":-540,"elapsed":26443,"user":{"displayName":"조윤주","userId":"03220839207625740811"}},"outputId":"5049dfcf-35ba-4f7f-f584-40451bab57e0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Running on TPU\n"]}]},{"cell_type":"code","source":["# 데이터셋 로드 함수\n","def load_npy_file(file_path):\n","    return np.load(file_path)\n","def create_dataset_from_directory(directory, batch_size=32, shuffle=True):\n","    file_paths = []\n","    labels = []\n","    class_names = sorted(os.listdir(directory))\n","\n","    for label, class_name in enumerate(class_names):\n","        class_dir = os.path.join(directory, class_name)\n","        for file_name in os.listdir(class_dir):\n","            if file_name.endswith('.npy'):\n","                file_paths.append(os.path.join(class_dir, file_name))\n","                labels.append(label)\n","\n","    file_paths = np.array(file_paths)\n","    labels = np.array(labels)\n","\n","    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n","\n","    def load_and_preprocess_image(file_path, label):\n","        image = tf.numpy_function(load_npy_file, [file_path], tf.float32)\n","        image = tf.reshape(image, [300, 300, 3])  # 원본 이미지의 예상 shape을 지정합니다.\n","        image = tf.image.resize(image, (224, 224))  # 이미지 크기 조정 (224x224)\n","        image = image / 255.0  # 정규화\n","        return image, label\n","\n","    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","\n","    if shuffle:\n","        dataset = dataset.shuffle(buffer_size=len(file_paths))\n","\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","\n","    return dataset, class_names  # 이 부분에서 dataset과 class_names를 반환합니다.\n"],"metadata":{"id":"tZXKIjCUmn0Z","executionInfo":{"status":"ok","timestamp":1724221572567,"user_tz":-540,"elapsed":327,"user":{"displayName":"조윤주","userId":"03220839207625740811"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# 데이터 경로 설정\n","train_dir = '/content/drive/MyDrive/ToyProject/preprocessed_images_b3/train'\n","val_dir = '/content/drive/MyDrive/ToyProject/preprocessed_images_b3/val'"],"metadata":{"id":"8Vjwbz-0m73P","executionInfo":{"status":"ok","timestamp":1724221580197,"user_tz":-540,"elapsed":332,"user":{"displayName":"조윤주","userId":"03220839207625740811"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# 데이터셋 생성\n","train_dataset, class_names = create_dataset_from_directory(train_dir, batch_size=256, shuffle=True)\n","\n","# 모델 정의 및 학습\n","with tf.distribute.get_strategy().scope():\n","    model = Sequential([\n","        EfficientNetB3(weights='imagenet', include_top=False, input_shape=(224, 224, 3), pooling='max'),\n","        BatchNormalization(),\n","        Dense(256, activation='relu'),\n","        Dropout(0.3),  # Dropout 비율 낮춤\n","        Dense(len(class_names), activation='softmax')\n","    ])\n","\n","    model.compile(optimizer=Adamax(learning_rate=0.0001),  # 학습률 낮춤\n","                  loss='sparse_categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    # 콜백 설정\n","    early_stopping = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n","    model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='loss')  # monitor를 'loss'로 변경\n","\n","    # 모델 학습\n","    history = model.fit(\n","        train_dataset,\n","        epochs=20,\n","        callbacks=[early_stopping, model_checkpoint]\n","    )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":557},"id":"bedxPccrm-tV","executionInfo":{"status":"error","timestamp":1724223726460,"user_tz":-540,"elapsed":29507,"user":{"displayName":"조윤주","userId":"03220839207625740811"}},"outputId":"26abe12d-83ab-4313-cae4-79399710fc5d"},"execution_count":4,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n","43941136/43941136 [==============================] - 0s 0us/step\n","Epoch 1/20\n","30/30 [==============================] - ETA: 0s - loss: 2.2424 - accuracy: 0.2173 "]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["30/30 [==============================] - 795s 21s/step - loss: 2.2424 - accuracy: 0.2173\n","Epoch 2/20\n","30/30 [==============================] - 669s 21s/step - loss: 1.9898 - accuracy: 0.2481\n","Epoch 3/20\n","28/30 [===========================>..] - ETA: 44s - loss: 1.8543 - accuracy: 0.2783 "]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-4f2bb602b1f4>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# 모델 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     history = model.fit(\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eh4vGt48l8b_","executionInfo":{"status":"ok","timestamp":1724221235349,"user_tz":-540,"elapsed":17862,"user":{"displayName":"조윤주","userId":"03220839207625740811"}},"outputId":"5dfd2c29-c6e1-4ffb-ae62-9df0c028a188"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras.applications import EfficientNetB3\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adamax\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","import time\n","\n","# Define possible hyperparameter values\n","batch_sizes = [16, 32, 64]\n","learning_rates = [0.0001, 0.001, 0.01]\n","\n","# Define a dictionary to store results\n","results = {}\n","\n","# Function to create and compile the model\n","def create_model(input_shape, learning_rate):\n","    model = Sequential([\n","        EfficientNetB3(weights='imagenet', include_top=False, input_shape=input_shape, pooling='max'),\n","        BatchNormalization(),\n","        Dense(256, activation='relu'),\n","        Dropout(0.3),\n","        Dense(len(class_names), activation='softmax')\n","    ])\n","\n","    model.compile(optimizer=Adamax(learning_rate=learning_rate),\n","                  loss='sparse_categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    return model\n","\n","# Function to perform grid search\n","def grid_search(train_dataset, input_shape):\n","    best_accuracy = 0\n","    best_params = {}\n","\n","    for batch_size in batch_sizes:\n","        for learning_rate in learning_rates:\n","            print(f\"Training with batch_size={batch_size} and learning_rate={learning_rate}\")\n","\n","            # Prepare the model\n","            model = create_model(input_shape, learning_rate)\n","\n","            # Set callbacks\n","            early_stopping = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n","            model_checkpoint = ModelCheckpoint(f'best_model_bs{batch_size}_lr{learning_rate}.h5', save_best_only=True, monitor='loss')\n","\n","            # Train the model\n","            start_time = time.time()\n","            history = model.fit(\n","                train_dataset,\n","                epochs=20,\n","                callbacks=[early_stopping, model_checkpoint],\n","                batch_size=batch_size,\n","                verbose=1\n","            )\n","            end_time = time.time()\n","            duration = end_time - start_time\n","\n","            # Get the best accuracy from training\n","            max_accuracy = max(history.history['accuracy'])\n","\n","            # Store results\n","            results[(batch_size, learning_rate)] = {\n","                'accuracy': max_accuracy,\n","                'duration': duration,\n","                'model_file': f'best_model_bs{batch_size}_lr{learning_rate}.h5'\n","            }\n","\n","            # Update best parameters\n","            if max_accuracy > best_accuracy:\n","                best_accuracy = max_accuracy\n","                best_params = {'batch_size': batch_size, 'learning_rate': learning_rate}\n","\n","    print(\"Best Hyperparameters:\")\n","    print(f\"Batch Size: {best_params['batch_size']}, Learning Rate: {best_params['learning_rate']}\")\n","    print(f\"Best Accuracy: {best_accuracy}\")\n","\n","    return best_params, results\n","\n","# Assume train_dataset is already created and input_shape is defined\n","input_shape = (224, 224, 3)\n","best_params, results = grid_search(train_dataset, input_shape)\n","\n","# Optionally, you can save the results to a file for further analysis\n","import json\n","with open('grid_search_results.json', 'w') as f:\n","    json.dump(results, f, indent=4)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eZl1L41kvhKM","outputId":"d09e2eb3-6aa1-46c1-b665-d708c456ad0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training with batch_size=16 and learning_rate=0.0001\n","Epoch 1/20\n","30/30 [==============================] - 696s 21s/step - loss: 2.1386 - accuracy: 0.2290\n","Epoch 2/20\n","30/30 [==============================] - 668s 21s/step - loss: 1.9373 - accuracy: 0.2672\n","Epoch 3/20\n","30/30 [==============================] - 663s 21s/step - loss: 1.8587 - accuracy: 0.2799\n","Epoch 4/20\n","30/30 [==============================] - 666s 21s/step - loss: 1.7487 - accuracy: 0.3130\n","Epoch 5/20\n","30/30 [==============================] - 666s 21s/step - loss: 1.6979 - accuracy: 0.3225\n","Epoch 6/20\n","30/30 [==============================] - 669s 21s/step - loss: 1.7135 - accuracy: 0.3137\n","Epoch 7/20\n","30/30 [==============================] - 668s 21s/step - loss: 1.7054 - accuracy: 0.3225\n","Epoch 8/20\n","30/30 [==============================] - 669s 21s/step - loss: 1.6151 - accuracy: 0.3421\n","Epoch 9/20\n","30/30 [==============================] - 668s 21s/step - loss: 1.6044 - accuracy: 0.3454\n","Epoch 10/20\n","30/30 [==============================] - 669s 21s/step - loss: 1.5892 - accuracy: 0.3547\n","Epoch 11/20\n","30/30 [==============================] - 673s 21s/step - loss: 1.5233 - accuracy: 0.3747\n","Epoch 12/20\n","30/30 [==============================] - 672s 21s/step - loss: 1.5359 - accuracy: 0.3657\n","Epoch 13/20\n","30/30 [==============================] - 669s 21s/step - loss: 1.4727 - accuracy: 0.3968\n","Epoch 14/20\n","30/30 [==============================] - 673s 22s/step - loss: 1.4414 - accuracy: 0.4087\n","Epoch 15/20\n","30/30 [==============================] - 674s 22s/step - loss: 1.4193 - accuracy: 0.4185\n","Epoch 16/20\n","30/30 [==============================] - 674s 22s/step - loss: 1.3925 - accuracy: 0.4182\n","Epoch 17/20\n","30/30 [==============================] - 676s 22s/step - loss: 1.3706 - accuracy: 0.4389\n","Epoch 18/20\n","30/30 [==============================] - 672s 22s/step - loss: 1.3237 - accuracy: 0.4625\n","Epoch 19/20\n","30/30 [==============================] - 674s 22s/step - loss: 1.3524 - accuracy: 0.4484\n","Epoch 20/20\n","30/30 [==============================] - 673s 22s/step - loss: 1.4492 - accuracy: 0.4134\n","Training with batch_size=16 and learning_rate=0.001\n","Epoch 1/20\n","30/30 [==============================] - 698s 21s/step - loss: 2.0017 - accuracy: 0.2729\n","Epoch 2/20\n","21/30 [====================>.........] - ETA: 3:19 - loss: 1.6841 - accuracy: 0.3276"]}]}]}